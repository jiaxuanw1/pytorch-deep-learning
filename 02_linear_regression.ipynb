{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxyEW38Ff9JJ2LJZOAAhxI"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Linear regression**\n",
        "- Create a model that predicts **target variables** by looking at **input variables**\n",
        "- Our model:\n",
        "  - Target variables: crop yields for apples and oranges\n",
        "  - Input variables or features: average temperature, rainfall, humidity\n",
        "- Each target var is estimated to be weighted sum of input vars, offset by a constant (bias):\n",
        "\n",
        "```\n",
        "yield_apple = w11 * temp + w12 * rainfall + w13 * humidity + b1\n",
        "yield_orange = w21 * temp + w22 * rainfall + w23 * humidity + b2\n",
        "```\n",
        "- i.e. each target var is a linear function of all input vars\n",
        "- *Learning* = using training data to find **weights** and **biases** that result in accurate predictions for new data\n",
        "- *Training* = start w/ random weights, adjust them slightly many times using **gradient descent**\n"
      ],
      "metadata": {
        "id": "aaQcUz2Z3yUr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xKdQXAYD3Y3i"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training data**\n",
        "- Each row is a data point\n",
        "- Each column is a variable"
      ],
      "metadata": {
        "id": "7JPWGm9775OM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inputs (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70]], dtype='float32')\n",
        "\n",
        "# targets (apples, oranges)\n",
        "targets = np.array([[56, 70],\n",
        "                    [81, 101],\n",
        "                    [119, 113],\n",
        "                    [22, 37],\n",
        "                    [103, 119]], dtype='float32')\n",
        "\n",
        "# separated inputs and targets because we'll operate on them separately\n",
        "\n",
        "# use floating point nums because model will make non-integer predictions\n",
        "# integers are harder to work with bc not continuous"
      ],
      "metadata": {
        "id": "QliW-xof7bju"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# typically read in training data from CSV as numpy arrays, do some processing,\n",
        "# and convert to pytorch tensors\n",
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TThj0zCc8N2c",
        "outputId": "d4f3bfba-7acd-4fd1-cdb1-817e534ed8eb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]])\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 113.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear regression model from scratch**"
      ],
      "metadata": {
        "id": "rYvo8dQw-Xcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# notice: \n",
        "# weights form a matrix w/ num rows = num targets, num cols = num input vars\n",
        "# biases form a vector w/ num rows = num targets\n",
        "\n",
        "# start with random weights and biases\n",
        "w = torch.randn(2, 3, requires_grad=True)\n",
        "b = torch.randn(2, requires_grad=True)\n",
        "# torch.randn chooses elements from normal distribution (mean 0, stdev 1)\n",
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8r3BuCp-XET",
        "outputId": "3523817c-5279-4519-9018-95dc1d9ea1b7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2.1329, -0.1202,  0.9868],\n",
            "        [-2.2505,  0.5090,  1.4815]], requires_grad=True)\n",
            "tensor([-0.6191, -1.2895], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# matrix mult of inputs (x) with weights w (transposed), then add bias b\n",
        "def model(x):\n",
        "  # @ represents matrix mult in pytorch\n",
        "  # .t() returns transpose of tensor\n",
        "  return x @ w.t() + b"
      ],
      "metadata": {
        "id": "3sDcAktRAKR-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate predictions\n",
        "preds = model(inputs)\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-36qfbZTBN_C",
        "outputId": "5e0b7878-4672-46ee-f335-53860b3244e8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 189.4614,  -67.7708],\n",
            "        [ 246.0520,  -66.4800],\n",
            "        [ 226.0715,  -42.9540],\n",
            "        [ 248.2786, -154.1400],\n",
            "        [ 204.0879,   -4.0080]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compare with targets\n",
        "print(targets)\n",
        "# random weights and biases, so pretty bad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fetRlooHBN1_",
        "outputId": "ab5573e4-8f2a-46cb-d6ae-09f9727effc6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 113.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loss function**\n",
        "- Evaluate model by comparing prediction w/ actual targets:\n",
        "  - Calculate difference between preds and targets\n",
        "  - Square all elements to make all positive\n",
        "  - Calculate average of resulting elements\n",
        "- Result is number called **mean squared error** (MSE)\n",
        "- Called **loss**: higher loss = higher error = worse model"
      ],
      "metadata": {
        "id": "xeULdNYEBk-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MSE loss function\n",
        "def mse(t1, t2):\n",
        "  diff = t1 - t2\n",
        "  return torch.sum(diff * diff) / diff.numel() # .numel = num elements"
      ],
      "metadata": {
        "id": "0uv4joSxCmdz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute loss\n",
        "loss = mse(preds, targets)\n",
        "print(loss)\n",
        "\n",
        "# this means on average, each element in prediction differs from actual target \n",
        "# by about sqrt(loss)\n",
        "\n",
        "# preds is a function of our weights and biases (inputs are fixed)\n",
        "# targets are also fixed, so...\n",
        "# loss is a function of our weights and biases"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akHciCTFDoKB",
        "outputId": "411b2bf7-d2ae-4554-92c3-bbcd0f238ddd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(24095.6680, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compute gradients**"
      ],
      "metadata": {
        "id": "KHv9oKFTERhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compute gradients w.r.t. weights and biases\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "ZGE3ZRrrFBdJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gradients stored in .grad property of respective tensors\n",
        "# note that derivative w.r.t. matrix is a matrix w/ same dimensions\n",
        "print(w)\n",
        "print(w.grad)\n",
        "# each entry in gradient matrix is partial derivative of loss w.r.t.\n",
        "# corresponding entry in weights matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUUJtwpwFG_2",
        "outputId": "d0b2767a-4dca-4834-bf5f-1e3176042a20"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2.1329, -0.1202,  0.9868],\n",
            "        [-2.2505,  0.5090,  1.4815]], requires_grad=True)\n",
            "tensor([[ 12826.6240,  11449.6992,   7592.1562],\n",
            "        [-13369.9570, -12978.9023,  -8274.1885]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- If gradient > 0:\n",
        "  - Increase weight --> increase loss\n",
        "  - Decrease weight --> decrease loss (goal)\n",
        "- If gradient < 0:\n",
        "  - Increase weight --> decrease loss (goal)\n",
        "  - Decrease weight --> increase loss\n",
        "- To decrease loss, need to change weight in opposite direction as gradient\n",
        "- Resulting change in loss is proportional to gradient value"
      ],
      "metadata": {
        "id": "Sdz4Qid3HbH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reset gradients to zero\n",
        "# needed bc pytorch adds gradient values each time .backward() is called\n",
        "w.grad.zero_()\n",
        "b.grad.zero_()\n",
        "\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "id": "9zxlXW-nHDyz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6b64d13-8502-4078-a4a8-12bda82ac05a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adjust weights and biases using gradient descent**\n",
        "1. Generate predictions\n",
        "2. Calculate loss\n",
        "3. Compute gradients w.r.t. weights and biases\n",
        "4. Adjust weights and biases - subtract proportional to gradient\n",
        "5. Reset gradients to 0"
      ],
      "metadata": {
        "id": "09e8zhIlIvn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate predictions\n",
        "preds = model(inputs)\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8jUANPdJLRU",
        "outputId": "2050aff8-f1ef-43fe-d656-c1a096f3195a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 189.4614,  -67.7708],\n",
            "        [ 246.0520,  -66.4800],\n",
            "        [ 226.0715,  -42.9540],\n",
            "        [ 248.2786, -154.1400],\n",
            "        [ 204.0879,   -4.0080]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate loss\n",
        "loss = mse(preds, targets)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpYjEDarJPZR",
        "outputId": "b853b5fb-61ba-4103-b689-330b8ed30352"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(24095.6680, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute gradients\n",
        "loss.backward()\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dq6eoTDQJXQV",
        "outputId": "bb8e99a0-3203-4367-bcd3-a0b3ae0b096e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 12826.6240,  11449.6992,   7592.1562],\n",
            "        [-13369.9570, -12978.9023,  -8274.1885]])\n",
            "tensor([ 146.5903, -155.0706])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adjust weights and biases, then reset gradients\n",
        "\n",
        "# pytorch will continue to track gradient values as w and b are updated\n",
        "# use torch.no_grad() to tell pytorch not to track/modify gradients\n",
        "with torch.no_grad():\n",
        "  # subtract small quantity (10^-5 in this case) proportional to gradient\n",
        "  # use small number to ensure we don't overcorrect and change weights too much\n",
        "  # number is called \"learning rate\" of the algorithm\n",
        "  w -= w.grad * 1e-5\n",
        "  b -= b.grad * 1e-5\n",
        "  # reset gradients to zero to avoid affecting future computations\n",
        "  w.grad.zero_()\n",
        "  b.grad.zero_()"
      ],
      "metadata": {
        "id": "nRCrscOQJb6F"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# look at new weights and biases\n",
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1X7sU8wfLO5A",
        "outputId": "65544003-e5c1-417d-e5ab-42557661212e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2.0046, -0.2347,  0.9109],\n",
            "        [-2.1168,  0.6388,  1.5642]], requires_grad=True)\n",
            "tensor([-0.6206, -1.2879], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with the new weights and biases, model should now have lower loss\n",
        "preds = model(inputs)\n",
        "loss = mse(preds, targets)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4NipQsWLpX2",
        "outputId": "039381ce-d76c-4281-b5c6-6a5baf441263"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(17091.5508, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train for multiple epochs**\n",
        " - To further reduce loss, keep repeating this process of adjusting weights and biases using the gradients\n",
        " - Each iteration is called an **epoch**"
      ],
      "metadata": {
        "id": "5GAIcTNUL8y9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train for 1000 epochs\n",
        "for i in range(1000):\n",
        "  # generate predictions\n",
        "  preds = model(inputs)\n",
        "  # calculate loss\n",
        "  loss = mse(preds, targets)\n",
        "  # calculate gradients\n",
        "  loss.backward()\n",
        "  with torch.no_grad():\n",
        "    # adjust weights and biases\n",
        "    w -= w.grad * 1e-5\n",
        "    b -= b.grad * 1e-5\n",
        "    # reset gradients to zero\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()"
      ],
      "metadata": {
        "id": "xbsJNWXSMbev"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate new loss\n",
        "preds = model(inputs)\n",
        "loss = mse(preds, targets)\n",
        "print(loss) # much better!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PQCX9SoNDNJ",
        "outputId": "c5019534-9dfc-4816-da67-9e686712c9b1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.7933, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# new predictions\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XU2mkbAVNjgQ",
        "outputId": "34f87b09-26e6-405e-cb5b-55bf6ba38842"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 57.0545,  66.8739],\n",
            "        [ 82.3012, 100.8705],\n",
            "        [118.6544, 113.2716],\n",
            "        [ 21.0794,  38.1854],\n",
            "        [101.9591, 120.3450]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compare with targets\n",
        "print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0W95OEsNowL",
        "outputId": "595c7e23-0c9d-4e0d-cc87-b4fa663e4c31"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 113.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ]
    }
  ]
}